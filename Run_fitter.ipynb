{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notebook to run the fitter on multiple ramps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ramp_utils.ramp import RampTimeSeq,RampMeasurement\n",
    "from ramp_utils.fitter import IterativeFitter\n",
    "import time, sys, pickle, bz2\n",
    "from multiprocessing import Pool\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the working directory for saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirsave = '/user/gennaro/Functional_work/Up_the_ramp_myfork/Simulations_results/'\n",
    "filename = 'Test_1.pbz2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are two auxiliary function used to generate CRhits \n",
    "#### A good number for WFC3 can be found in http://www.stsci.edu/hst/wfc3/documents/ISRs/WFC3-2009-40.pdf, with ~ 2.5e-5 hits per second per pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateCR_DNs(size):\n",
    "    '''\n",
    "    Just generate random uniform DNs\n",
    "    '''\n",
    "    return 1000.*np.random.uniform(size=size)\n",
    "\n",
    "def generateCR(myramp,CRrate=2.5e-5):\n",
    "    '''\n",
    "    Main CR generation function that generates CR hit times and depositied counts\n",
    "    \n",
    "    :CRrate:\n",
    "        rate of CR hits in hits/second\n",
    "    '''\n",
    "    \n",
    "    myCRnumber = np.random.poisson(lam=CRrate*myramp.read_times[-1])\n",
    "\n",
    "    if myCRnumber > 0:\n",
    "        mytimes = myramp.read_times[-1]*np.random.uniform(size=myCRnumber)\n",
    "        mycounts = generateCR_DNs(myCRnumber)\n",
    "        myCRdict = {'times':mytimes.tolist(),'counts':mycounts.tolist()}\n",
    "    else:\n",
    "        myCRdict = None\n",
    "\n",
    "    return myCRdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary function to generate cumulative background electrons\n",
    "Used to test the fitter with non-constant flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vbg_electrons(times,vbg_cr,meas,mean_bg_cr=None):\n",
    "    '''\n",
    "    Given a tabulated form for the variable background time dependency,\n",
    "    generate a number of electrons per each read interval in the ramp\n",
    "    \n",
    "    :times:\n",
    "        times at which the countrate is tabulated\n",
    "    \n",
    "    :vbg_cr:\n",
    "        values of the time variable background at those times   \n",
    "    \n",
    "    :meas:\n",
    "        a RampMeasurement object\n",
    "    \n",
    "    :mean_bg_cr:\n",
    "        the mean value for normalizing the countrate within the interval    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    #Create an interpolator from the tabulated values and interpolate at the ramp read times\n",
    "    bg_int = interp1d(times,vbg_cr,'quadratic')\n",
    "    varbg = bg_int(meas.RTS.read_times)\n",
    "\n",
    "    #Normalize if requested\n",
    "    if mean_bg_cr is not None:\n",
    "        dt = meas.RTS.read_times[-1]-meas.RTS.read_times[0]\n",
    "        t_avg = np.trapz(varbg,meas.RTS.read_times) / dt\n",
    "        varbg = varbg/t_avg * mean_bg_cr\n",
    "\n",
    "    #Get the total accumulated electrons\n",
    "    bg_e=[0]\n",
    "    bg_e.extend([np.random.poisson(lam=vb*dt) for vb,dt in zip(0.5*(varbg[1:]+varbg[:-1]),meas.RTS.read_times[1:]-meas.RTS.read_times[:-1]) ])\n",
    "    bg_e = np.asarray(bg_e)\n",
    "    \n",
    "    return np.cumsum(bg_e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the read sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt,nf,ns,ng = 6.,1,0,17\n",
    "myramp1 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "dt,nf,ns,ng = 8.,1,0,13\n",
    "myramp2 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "dt,nf,ns,ng = 12.,1,0,9\n",
    "myramp3 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "dt,nf,ns,ng = 16.,1,0,7\n",
    "myramp4 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "dt,nf,ns,ng = 24.,1,0,5\n",
    "myramp5 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "\n",
    "myramp6 = RampTimeSeq('HST/WFC3/IR',15,samp_seq='SPARS100') \n",
    "\n",
    "\n",
    "for ramp in [myramp6]:\n",
    "    ramp.test_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the detector charachteristics\n",
    "This step is necessary when the ramps are of **GENERIC** type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gain=1\n",
    "RON=20\n",
    "KTC=50\n",
    "bias=10000\n",
    "full_well=100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the properties of the measurements on which to run the fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myfluxes   = [   0.25,     1.,      4,     16,     64,    0.5,    0.5,   0.5,     0.5,    0.5]\n",
    "myramps    = [myramp6,myramp6,myramp6,myramp6,myramp6,myramp6,myramp6,myramp6,myramp6,myramp6]\n",
    "myCRrates  = [   5e-4,   5e-4,   5e-4,   5e-4,   5e-4,     0.,     0.,    0.,      0.,     0.]\n",
    "\n",
    "tbg  = np.linspace(0,1500,10)\n",
    "cbg  = np.array([1.0,1.2,1.5,1.3,1.7,2.0,2.2,2.4,2.0,1.5])\n",
    "cbg2 = np.array([1.0,1.5,1.9,2.3,2.5,2.7,3.2,3.0,2.5,2.0])\n",
    "\n",
    "mybgs      = [   None,   None,   None,   None,   None,  None,\n",
    "         {'times':tbg,'vbg_cr':cbg,'mean_bg_cr':0.5},\n",
    "         {'times':tbg,'vbg_cr':cbg,'mean_bg_cr':1.},\n",
    "         {'times':tbg,'vbg_cr':cbg,'mean_bg_cr':2.},\n",
    "         {'times':tbg,'vbg_cr':cbg,'mean_bg_cr':1.}\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the fitter method and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitpars = {'one_iteration_method':'Nelder-Mead'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntest    = 2000\n",
    "printevery = 10\n",
    "n_jobs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the fitter on multiple ramps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that does the fit of individual measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_fit(j,k,flux,ramp,CRrate,extra_bg):\n",
    "\n",
    "    \n",
    "    if ((j*ntest+k) % printevery) == 0:\n",
    "        print(\"Starting fit {} out of {}\".format(j*ntest+k, len(myfluxes)*ntest))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    CRdict = generateCR(ramp,CRrate=CRrate)\n",
    "        \n",
    "    if ramp.detector == 'GENERIC':\n",
    "        meas = RampMeasurement(ramp,flux,gain=gain,RON=RON,KTC=KTC,bias=bias,full_well=full_well,CRdict=CRdict)\n",
    "    else:\n",
    "        meas = RampMeasurement(ramp,flux,CRdict=CRdict)\n",
    "\n",
    "    if extra_bg is not None:\n",
    "        ebh = get_vbg_electrons(extra_bg['times'],extra_bg['vbg_cr'],meas,mean_bg_cr=extra_bg['mean_bg_cr'])   \n",
    "        meas.add_background(ebh)\n",
    "    else:\n",
    "        ebh = None\n",
    "\n",
    "    fitter = IterativeFitter(meas,fitpars = fitpars)\n",
    "    error,counter, goodints, crloops_counter  = fitter.perform_fit()\n",
    "    outerate = fitter.mean_electron_rate\n",
    "    fitter.goodness_of_fit(mode='Squared-deviations')\n",
    "    gof_stat = fitter.gof_stat\n",
    "    gof_pval = fitter.gof_pval\n",
    "                \n",
    "            \n",
    "\n",
    "    return j,k,goodints,CRdict,meas,counter,error,crloops_counter,outerate,gof_stat,gof_pval,extra_bg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell that iterates over all the input fluxes/ramp/background combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [ [j,k,mytuple[0],mytuple[1],mytuple[2],mytuple[3]] for j,mytuple in enumerate(zip(myfluxes,myramps,myCRrates,mybgs)) for k in range(ntest)]\n",
    "\n",
    "mypool = Pool(n_jobs)\n",
    "\n",
    "ts = time.time()\n",
    "j_l,k_l,goodints_l,CRdict_l,meas_l,counter_l,error_l,crloops_counter_l,outerate_l,gof_stat_l,gof_pval_l,extra_bg_l = map(list, zip(*mypool.starmap(one_fit,inputs)))\n",
    "te = time.time()\n",
    "\n",
    "print('Elapsed time [minutes]: {}'.format((te-ts)/60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicttosave = {'myfluxes':myfluxes,\n",
    "              'myramps':myramps,\n",
    "              'myCRrates':myCRrates,\n",
    "              'mybgs':mybgs,\n",
    "              'j_l':j_l,\n",
    "              'k_l':k_l,\n",
    "              'goodints_l':goodints_l,\n",
    "              'CRdict_l':CRdict_l,\n",
    "              'meas_l':meas_l,\n",
    "              'counter_l':counter_l,\n",
    "              'error_l':error_l,\n",
    "              'crloops_counter_l':crloops_counter_l,\n",
    "              'outerate_l':outerate_l,\n",
    "              'gof_stat_l':gof_stat_l,\n",
    "              'gof_pval_l':gof_pval_l,\n",
    "              'extra_bg_l':extra_bg_l\n",
    "             }\n",
    "              \n",
    "with bz2.BZ2File(dirsave+filename, 'w') as f:\n",
    "        pickle.dump(dicttosave, f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
