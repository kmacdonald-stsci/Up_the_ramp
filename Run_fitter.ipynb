{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Notebook to run the fitter on multiple ramps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ramp_utils.ramp import RampTimeSeq,RampMeasurement\n",
    "from ramp_utils.fitter import IterativeFitter\n",
    "import time, sys, pickle, bz2, os\n",
    "from multiprocessing import Pool\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the working directory for saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirsave = '/user/gennaro/Functional_work/Up_the_ramp_myfork/Simulations_results/'\n",
    "testname = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_file = dirsave+'Test_'+testname+'_out.pbz2'\n",
    "inputs_file  = dirsave+'Test_'+testname+'_in.pbz2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These are two auxiliary function used to generate CRhits \n",
    "#### A good number for WFC3 can be found in http://www.stsci.edu/hst/wfc3/documents/ISRs/WFC3-2009-40.pdf, with ~ 2.5e-5 hits per second per pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateCR_DNs(size):\n",
    "    '''\n",
    "    Just generate random uniform DNs\n",
    "    '''\n",
    "    return 1000.*np.random.uniform(size=size)\n",
    "\n",
    "def generateCR(myramp,CRrate=2.5e-5):\n",
    "    '''\n",
    "    Main CR generation function that generates CR hit times and depositied counts\n",
    "    \n",
    "    :CRrate:\n",
    "        rate of CR hits in hits/second\n",
    "    '''\n",
    "    \n",
    "    myCRnumber = np.random.poisson(lam=CRrate*myramp.read_times[-1])\n",
    "\n",
    "    if myCRnumber > 0:\n",
    "        mytimes = myramp.read_times[-1]*np.random.uniform(size=myCRnumber)\n",
    "        mycounts = generateCR_DNs(myCRnumber)\n",
    "        myCRdict = {'times':mytimes.tolist(),'counts':mycounts.tolist()}\n",
    "    else:\n",
    "        myCRdict = None\n",
    "\n",
    "    return myCRdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary function to generate cumulative background electrons\n",
    "Used to test the fitter with non-constant flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vbg_electrons(times,vbg_cr,meas,mean_bg_cr=None):\n",
    "    '''\n",
    "    Given a tabulated form for the variable background time dependency,\n",
    "    generate a number of electrons per each read interval in the ramp\n",
    "    \n",
    "    :times:\n",
    "        times at which the countrate is tabulated\n",
    "    \n",
    "    :vbg_cr:\n",
    "        values of the time variable background at those times   \n",
    "    \n",
    "    :meas:\n",
    "        a RampMeasurement object\n",
    "    \n",
    "    :mean_bg_cr:\n",
    "        the mean value for normalizing the countrate within the interval    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    #Create an interpolator from the tabulated values and interpolate at the ramp read times\n",
    "    bg_int = interp1d(times,vbg_cr,'quadratic')\n",
    "    varbg = bg_int(meas.RTS.read_times)\n",
    "\n",
    "    #Normalize if requested\n",
    "    if mean_bg_cr is not None:\n",
    "        dt = meas.RTS.read_times[-1]-meas.RTS.read_times[0]\n",
    "        t_avg = np.trapz(varbg,meas.RTS.read_times) / dt\n",
    "        varbg = varbg/t_avg * mean_bg_cr\n",
    "\n",
    "    #Get the total accumulated electrons\n",
    "    bg_e=[0]\n",
    "    bg_e.extend([np.random.poisson(lam=vb*dt) for vb,dt in zip(0.5*(varbg[1:]+varbg[:-1]),meas.RTS.read_times[1:]-meas.RTS.read_times[:-1]) ])\n",
    "    bg_e = np.asarray(bg_e)\n",
    "    \n",
    "    return np.cumsum(bg_e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the read sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt,nf,ns,ng = 6.,1,0,17\n",
    "myramp1 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "dt,nf,ns,ng = 8.,1,0,13\n",
    "myramp2 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "dt,nf,ns,ng = 12.,1,0,9\n",
    "myramp3 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "dt,nf,ns,ng = 16.,1,0,7\n",
    "myramp4 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "dt,nf,ns,ng = 24.,1,0,5\n",
    "myramp5 = RampTimeSeq('GENERIC',ng,nframes=nf, nskips=ns, read_times=dt*np.arange(ng*(nf+ns)))\n",
    "\n",
    "\n",
    "myramp6 = RampTimeSeq('HST/WFC3/IR',15,samp_seq='SPARS100') \n",
    "\n",
    "\n",
    "for ramp in [myramp6]:\n",
    "    ramp.test_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the detector charachteristics\n",
    "This step is necessary when the ramps are of **GENERIC** type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gain=1\n",
    "RON=20\n",
    "KTC=50\n",
    "bias=10000\n",
    "full_well=100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the properties of the measurements on which to run the fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myfluxes   = [   0.05,     4,      64,    0.5,    0.5]\n",
    "myramps    = [myramp6,myramp6,myramp6,myramp6,myramp6]\n",
    "myCRrates  = [   5e-4,   5e-4,   5e-4,     0.,     0.]\n",
    "\n",
    "tbg  = np.linspace(0,1500,10)\n",
    "cbg  = np.array([1.0,1.2,1.5,1.3,1.7,2.0,2.2,2.4,2.0,1.5])\n",
    "\n",
    "mybgs      = [   None,   None,   None,   None, \n",
    "         {'times':tbg,'vbg_er':cbg,'mean_bg_er':1.},\n",
    "        ]\n",
    "\n",
    "\n",
    "if (len(myfluxes) == len(myramps) == len(myCRrates) == len(mybgs)) == False:\n",
    "    assert False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the fitter method and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitpars = {'one_iteration_method':'Nelder-Mead'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntest      = 100\n",
    "printevery = 50\n",
    "n_jobs     = 8\n",
    "chunksize  = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the fitter on multiple ramps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that does the fit of individual measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_fit(l,meas):\n",
    "\n",
    "    if (l % printevery) == 0:\n",
    "        print(\"Starting fit {} of {}\".format(l, len(meas_l)))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    fitter = IterativeFitter(meas,fitpars = fitpars)\n",
    "    error,counter, goodints, crloops_counter  = fitter.perform_fit()\n",
    "    outerate = fitter.mean_electron_rate\n",
    "    fitter.goodness_of_fit(mode='Squared-deviations')\n",
    "    gof_stat = fitter.gof_stat\n",
    "    gof_pval = fitter.gof_pval\n",
    "     \n",
    "    return goodints,counter,error,crloops_counter,outerate,gof_stat,gof_pval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that prepares the random measurement ramp given as set of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_meas(flux,ramp,CRrate,extra_bg):\n",
    "    \n",
    "    CRdict = generateCR(ramp,CRrate=CRrate)\n",
    "        \n",
    "    if ramp.detector == 'GENERIC':\n",
    "        meas = RampMeasurement(ramp,flux,gain=gain,RON=RON,KTC=KTC,bias=bias,full_well=full_well,CRdict=CRdict)\n",
    "    else:\n",
    "        meas = RampMeasurement(ramp,flux,CRdict=CRdict)\n",
    "\n",
    "    if extra_bg is not None:\n",
    "        ebh = get_vbg_electrons(extra_bg['times'],extra_bg['vbg_er'],meas,mean_bg_cr=extra_bg['mean_bg_er'])   \n",
    "        meas.add_background(ebh)\n",
    "    else:\n",
    "        ebh = None\n",
    "\n",
    "    return meas,CRdict,ebh\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell that iterates over all the input fluxes/ramp/background combinations to create measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(inputs_file) == True: \n",
    "    print('Input file already existing....loading')\n",
    "    with bz2.BZ2File(inputs_file, 'rb') as f:\n",
    "        dictoload  = pickle.load(f)\n",
    "    meas_l     = dictoload['meas_l']\n",
    "    myfluxes   = dictoload['myfluxes']\n",
    "    myramps    = dictoload['myramps']\n",
    "    myCRrates  = dictoload['myCRrates']\n",
    "    mybgs      = dictoload['mybgs']\n",
    "    CRdict_l   = dictoload['CRdict_l']\n",
    "    extra_bg_l = dictoload['extra_bg_l']\n",
    "    \n",
    "    del(dictoload)\n",
    "    \n",
    "else:\n",
    "    print('Creating inputs files')\n",
    "    mypool = Pool(n_jobs)\n",
    "\n",
    "    ts = time.time()\n",
    "    inputs = [ [mytuple[0],mytuple[1],mytuple[2],mytuple[3]] for mytuple in zip(myfluxes,myramps,myCRrates,mybgs) for k in range(ntest)]\n",
    "    meas_l, CRdict_l, extra_bg_l = map(list,zip(*mypool.starmap(one_meas,inputs,10)))\n",
    "    te = time.time()\n",
    "    dicttosave={'myfluxes':myfluxes,\n",
    "                'myramps':myramps,\n",
    "                'myCRrates':myCRrates,\n",
    "                'mybgs':mybgs,\n",
    "                'meas_l':meas_l,\n",
    "                'CRdict_l':CRdict_l,\n",
    "                'extra_bg_l':extra_bg_l\n",
    "                }\n",
    "    \n",
    "    with bz2.BZ2File(inputs_file, 'w') as f:\n",
    "        pickle.dump(dicttosave, f)\n",
    "    mypool.close()\n",
    "    mypool.join()\n",
    "    del(dictosave)\n",
    "    \n",
    "    print('Created inputs files, time elapsed: {} seconds'.format(te-ts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell that iterates over single measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypool = Pool(n_jobs)\n",
    "\n",
    "inputs = [ [l,meas] for l,meas in enumerate(meas_l)]\n",
    "ts = time.time()\n",
    "goodints_l,counter_l,error_l,crloops_counter_l,outerate_l,gof_stat_l,gof_pval_l = map(list, zip(*mypool.starmap(one_fit,inputs,chunksize)))\n",
    "te = time.time()\n",
    "\n",
    "mypool.close()\n",
    "mypool.join()\n",
    "print('Elapsed time [minutes]: {}'.format((te-ts)/60.))\n",
    "print('Time per fit [s]: {}'.format((te-ts)/len(myfluxes)/ntest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicttosave = {'goodints_l':goodints_l,\n",
    "              'counter_l':counter_l,\n",
    "              'error_l':error_l,\n",
    "              'crloops_counter_l':crloops_counter_l,\n",
    "              'outerate_l':outerate_l,\n",
    "              'gof_stat_l':gof_stat_l,\n",
    "              'gof_pval_l':gof_pval_l,\n",
    "             }\n",
    "\n",
    "with bz2.BZ2File(outputs_file, 'w') as f:\n",
    "        pickle.dump(dicttosave, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
