{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test whether the goodness of fit criterion developed in ramp_utils/fitter.py can succesfully identify bad fits in a couple of problematic wfc3 situation\n",
    "\n",
    "This notebook uses several features from the `nonlinear_bkg` notebook by J. Mack, which (is/ will soon be) included in wfc3tools notebook and/or stsci notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.io import fits\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The g.o.f. computing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The function that computes the likelihood of a ramp given the best fit value,\n",
    "in the assumption that the flux is constant.\n",
    "Can be used to \"reject\" the hypotesis that the flux is constant, and thus to provide a flag for reprocessing\n",
    "This is an adaptation of the goodness_of_fit method in the fitter.py class.\n",
    "\n",
    "Rationale: obtain the probability of observing the given differences in electron (from the IMA files),\n",
    "and compare such probability with the same probability for a certain number of random ramps,\n",
    "generated starting from the fitted flux value and given the read noise.\n",
    "It basically measures whether the observed electrons are consistent with poisson + read noise\n",
    "\n",
    "\n",
    "    :electron_rate: the mean flux (e/s) from flt files, a scalar\n",
    "    \n",
    "    :dt: time intervals, numpy array of length NSAMP-1\n",
    "    \n",
    "    :diffs: difference of electrons in read_j minus read_{j-1}, lenght NSAMP-1\n",
    "    \n",
    "    :good_intervals: intervals that were used in the fit, i.e. those w/o cosmic rays,\n",
    "                     numpy array of booleans, length NSAMP-1\n",
    "\n",
    "    :RON: the readout noise in electrons (per single read, not in CDS mode)\n",
    "    \n",
    "    :FW: full-well capacity\n",
    "    \n",
    "    :ncompare: the number of simulations from which to obtain probabilitites to be compared with the probability of the actual observation\n",
    "    \n",
    "    :nsig: number of sigmas to establish the range of integration for the Poisson*Gaussian integral\n",
    "'''\n",
    "\n",
    "\n",
    "from scipy.stats import poisson, norm\n",
    "\n",
    "def goodness_of_fit(electron_rate,dt,diffs,good_intervals,RON,FW=80000,ncompare=10000,nsig=3):\n",
    "    \n",
    "    \n",
    "    lprob = 0.\n",
    "\n",
    "    for i in range(len(dt)):\n",
    "        if good_intervals[i] == True:\n",
    "            gauss_distr = norm(loc=diffs[i]*dt[i],scale=np.sqrt(2)*RON)\n",
    "            mu = electron_rate*dt[i]\n",
    "            poiss_distr = poisson(mu=mu)\n",
    "\n",
    "            low  = np.floor(np.maximum(0,mu-nsig*np.sqrt(mu))).astype(np.int_)\n",
    "            high = np.ceil(np.minimum(FW,mu+nsig*np.sqrt(mu))).astype(np.int_)\n",
    "            integral_x = np.arange(low,high,1)\n",
    "\n",
    "            poiss_pmfs = poiss_distr.pmf(integral_x)\n",
    "            gauss_pdfs = gauss_distr.pdf(integral_x)            \n",
    "            prob=np.sum(poiss_pmfs*gauss_pdfs)\n",
    "            lprob += np.log(prob)\n",
    "\n",
    "    lprob_v = np.zeros(ncompare)\n",
    "    nh = norm(loc=0.,scale=np.sqrt(2)*RON)\n",
    "\n",
    "    for i in range(len(dt)):\n",
    "        if good_intervals[i] == True:\n",
    "            mu = electron_rate*dt[i]\n",
    "            poiss_distr = poisson(mu=mu)\n",
    "            low  = np.floor(np.maximum(0,mu-nsig*np.sqrt(mu))).astype(np.int_)\n",
    "            high = np.ceil(np.minimum(FW,mu+nsig*np.sqrt(mu))).astype(np.int_)\n",
    "\n",
    "            integral_x = np.arange(low,high,1)\n",
    "            poiss_pmfs = poiss_distr.pmf(integral_x)\n",
    "\n",
    "            prob_v = np.zeros(ncompare)\n",
    "            rv = poiss_distr.rvs(size=ncompare) + nh.rvs(size=ncompare)\n",
    "            for k in range(ncompare):\n",
    "                gauss_distr = norm(loc=rv[k],scale=np.sqrt(2)*RON)\n",
    "                gauss_pdfs = gauss_distr.pdf(integral_x)\n",
    "                prob_v[k] = np.sum(poiss_pmfs*gauss_pdfs)\n",
    "\n",
    "            lprob_v += np.log(prob_v)                                                      \n",
    "\n",
    "    BM = lprob > lprob_v\n",
    "    pval = np.sum(BM).astype(np.float_)/ncompare\n",
    "    \n",
    "    return lprob,pval\n",
    "\n",
    "def goodness_of_fit_gauss(electron_rate,sigma_electron_rate,dt,diffs,good_intervals,RON=20,ncompare=10000):\n",
    "\n",
    "    lprob = 0.\n",
    "    lprob_v = np.zeros(ncompare)\n",
    "    for i in range(len(dt)):\n",
    "        if good_intervals[i] == True:\n",
    "            err =  np.sqrt( (sigma_electron_rate*dt[i])**2 + 2*RON**2)\n",
    "            gauss_distr = norm(loc=electron_rate*dt[i],scale=err)\n",
    "            \n",
    "            lprob += np.log(gauss_distr.pdf(diffs[i]*dt[i]))\n",
    "\n",
    "            rv = gauss_distr.rvs(size=ncompare)\n",
    "            lprob_v += np.log(gauss_distr.pdf(rv)) \n",
    "\n",
    "\n",
    "    BM = lprob > lprob_v\n",
    "    pval = np.sum(BM).astype(np.float_)/ncompare\n",
    "\n",
    "    return lprob,pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests using simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to add variable background to a ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def get_vbg_electrons(times,vbg_cr,meas,mean_bg_cr=None):\n",
    "    '''\n",
    "    Given a tabulated form for the variable background time dependency,\n",
    "    generate a number of electrons per each read interval in the ramp\n",
    "    \n",
    "    :times:\n",
    "        times at which the countrate is tabulated\n",
    "    \n",
    "    :vbg_cr:\n",
    "        values of the time variable background at those times   \n",
    "    \n",
    "    :meas:\n",
    "        a RampMeasurement object\n",
    "    \n",
    "    :mean_bg_cr:\n",
    "        the mean value for normalizing the countrate within the interval    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    #Create an interpolator from the tabulated values and interpolate at the ramp read times\n",
    "    bg_int = interp1d(times,vbg_cr,'quadratic')\n",
    "    varbg = bg_int(meas.RTS.read_times)\n",
    "\n",
    "    #Normalize if requested\n",
    "    if mean_bg_cr is not None:\n",
    "        dt = meas.RTS.read_times[-1]-meas.RTS.read_times[0]\n",
    "        t_avg = np.trapz(varbg,meas.RTS.read_times) / dt\n",
    "        varbg = varbg/t_avg * mean_bg_cr\n",
    "\n",
    "    #Get the total accumulated electrons\n",
    "    bg_e=[0]\n",
    "    bg_e.extend([np.random.poisson(lam=vb*dt) for vb,dt in zip(0.5*(varbg[1:]+varbg[:-1]),meas.RTS.read_times[1:]-meas.RTS.read_times[:-1]) ])\n",
    "    bg_e = np.asarray(bg_e)\n",
    "    \n",
    "    return np.cumsum(bg_e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate a ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ramp_utils.ramp import RampTimeSeq,RampMeasurement\n",
    "from ramp_utils.fitter import IterativeFitter\n",
    "\n",
    "\n",
    "myramp = RampTimeSeq('HST/WFC3/IR',15,samp_seq='SPARS100') # a WFC3 ramp with 15 samples and a SPARS100 sequence \n",
    "myflux = 1\n",
    "CRdict = {'times':[220., 700.,980],'counts':[300,20,290]}\n",
    "\n",
    "mymeas = RampMeasurement(myramp,myflux,CRdict=CRdict)\n",
    "\n",
    "mymeas.test_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If needed, add variable background and/or cosmic rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbg  = np.linspace(0,1500,10)\n",
    "cbg  = np.array([1.0,1.2,1.5,1.3,2.0,3.5,4.7,3.4,2.0,1.5])\n",
    "extra_bg= {'times':tbg,'vbg_er':np.power(cbg,1.0),'mean_bg_er':1.0}\n",
    "extra_bg=None\n",
    "\n",
    "if extra_bg is not None:\n",
    "    ebh = get_vbg_electrons(extra_bg['times'],extra_bg['vbg_er'],mymeas,mean_bg_cr=extra_bg['mean_bg_er'])   \n",
    "    mymeas.add_background(ebh)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Perform the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfitter = IterativeFitter(mymeas,fitpars={'one_iteration_method':'Nelder-Mead'})\n",
    "err, count, gi, crlcount = myfitter.perform_fit(CRthr=4)\n",
    "myfitter.test_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G.o.f. according to my original method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfitter.goodness_of_fit(mode='full-likelihood')\n",
    "print(myfitter.mean_electron_rate, myfitter.gof_stat,myfitter.gof_pval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G.o.f. according to the modified version that can be used with ***calwf3***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = myfitter.RM.RTS.group_times[1:]-myfitter.RM.RTS.group_times[:-1]\n",
    "diffs = (myfitter.RM.noisy_electrons_reads[1:]-myfitter.RM.noisy_electrons_reads[:-1])/dt\n",
    "good_intervals = gi\n",
    "electron_rate = myfitter.mean_electron_rate\n",
    "RON = myfitter.RM.RON_e\n",
    "lprob, pval = goodness_of_fit(electron_rate,dt,diffs,good_intervals,RON,FW=80000,ncompare=1000,nsig=3)\n",
    "print(lprob, pval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now do the test on real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and display a good and a \"bad\" image from program 12242, visit BF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Helium_data/'\n",
    "\n",
    "flt1=fits.getdata(path+'ibohbfb7q_flt.fits',ext=1)\n",
    "flt2=fits.getdata(path+'ibohbfb9q_flt.fits',ext=1)\n",
    "\n",
    "fig=plt.figure(figsize=(12,6))\n",
    "ax1=fig.add_subplot(1,2,1)\n",
    "ax2=fig.add_subplot(1,2,2)\n",
    "\n",
    "ax1.imshow(flt1, vmin=-0.25+np.nanmedian(flt1),vmax=.5+np.nanmedian(flt1),cmap='Greys_r',origin='lower')\n",
    "ax2.imshow(flt2, vmin=-0.25+np.nanmedian(flt2),vmax=.5+np.nanmedian(flt2),cmap='Greys_r',origin='lower')\n",
    "\n",
    "ax1.set_title('ibohbfb7q (Linear Bkg)',fontsize=20)\n",
    "ax2.set_title('ibohbfb9q (Non-linear Bkg)',fontsize=20)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange IMAs and FLTs to be fed to the g.o.f. routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function that takes a filename and read and rearranges the flt and ima file\n",
    "to be fed to the goodness of fit function\n",
    "'''\n",
    "\n",
    "\n",
    "def rearrange(path, rootname):\n",
    "\n",
    "    flt=fits.open(path+rootname+'_flt.fits')\n",
    "    ima=fits.open(path+rootname+'_ima.fits')\n",
    "    \n",
    "    wfc3ron = 0.25*(flt[0].header['READNSEA']+flt[0].header['READNSEB']+flt[0].header['READNSEC']+flt[0].header['READNSED'])\n",
    "   \n",
    "    ns = ima[0].header['NSAMP']\n",
    "    \n",
    "    diffs = np.empty([1014,1014,ns-1],dtype=np.float_)\n",
    "    gintv = np.ones([1014,1014,ns-1],dtype=np.bool_)\n",
    "    dt    = np.empty(ns-1)\n",
    "    mt    = np.empty(ns-1)\n",
    "    \n",
    "    for j in range(ns-1):\n",
    "        \n",
    "        te = ima['TIME',ns-j-1].header['PIXVALUE']\n",
    "        ts = ima['TIME',ns-j].header['PIXVALUE']\n",
    "        ee = ima['SCI',ns-j-1].data[5:-5,5:-5]\n",
    "        es = ima['SCI',ns-j].data[5:-5,5:-5]\n",
    "        ge = ima['DQ',ns-j-1].data[5:-5,5:-5]\n",
    "        gs = ima['DQ',ns-j].data[5:-5,5:-5]\n",
    "\n",
    "        diffs[:,:,j] = (te*ee-ts*es)/(te-ts)\n",
    "        \n",
    "        BM = (gs == 0) & (ge == 8192) \n",
    "        gintv[BM,j] = False\n",
    "        \n",
    "        dt[j] = te-ts\n",
    "        mt[j] = 0.5*(te+ts)\n",
    "     \n",
    "    rates = flt['SCI',1].data\n",
    "    fltdq = flt['DQ',1].data\n",
    "    error = flt['ERR',1].data\n",
    "    \n",
    "    diffs = diffs.reshape(-1, diffs.shape[-1])\n",
    "    gintv = gintv.reshape(-1, gintv.shape[-1])\n",
    "    rates = rates.flatten()\n",
    "    fltdq = fltdq.flatten()\n",
    "    error = error.flatten()\n",
    "    \n",
    "    return diffs,gintv,rates,fltdq,error,dt,mt,wfc3ron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test that the rearrangement works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,g,r,fdq,err,dt,mt,ron = rearrange(path,'ibohbfb7q')\n",
    "\n",
    "j,k = 5,9\n",
    "i = np.nonzero(~g[:,k]) # indexes of ramps that have a cosmic ray in read k\n",
    "           \n",
    "print(g[i[0][j],:]) # take the j-th of those pixel having cosmic rays in read k\n",
    "f=plt.figure()\n",
    "plt.scatter(mt,d[i[0][j],:],c=~g[i[0][j],:],cmap='winter');\n",
    "plt.axhline(r[i[0][j]],c='#bb3311');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the g.o.f. test on a list of wfc3 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "n_jobs = 30\n",
    "mypool = Pool(n_jobs)\n",
    "\n",
    "nmax = 10000000\n",
    "method = 'Gauss'\n",
    "results = []\n",
    "\n",
    "imlist = ['ibohbfb7q','ibohbfb9q']\n",
    "for rootname in imlist:    \n",
    "    \n",
    "    print('Starting',rootname)\n",
    "    diffs_l,good_intervals_l,electron_rate_l,fltdq_l,error_l,dt,mt,RON = rearrange(path,rootname)\n",
    "\n",
    "    if method == 'full':\n",
    "        inputs = [ [electron_rate,dt,diffs,good_intervals,RON,80000,100,3] \n",
    "                  for j,(electron_rate,diffs,good_intervals) in enumerate(zip(electron_rate_l,diffs_l,good_intervals_l))\n",
    "                  if j < nmax\n",
    "                 ]\n",
    "        ts = time.time()\n",
    "        lprob_l,pval_l = map(list, zip(*mypool.starmap(goodness_of_fit,inputs,5)))\n",
    "        te = time.time()\n",
    "        \n",
    "    elif method =='Gauss':\n",
    "        inputs = [ [electron_rate,error,dt,diffs,good_intervals,RON,1000] \n",
    "              for j,(electron_rate,error,diffs,good_intervals) in enumerate(zip(electron_rate_l,error_l,diffs_l,good_intervals_l))\n",
    "              if j < nmax\n",
    "             ]\n",
    "\n",
    "        ts = time.time()\n",
    "        lprob_l,pval_l = map(list, zip(*mypool.starmap(goodness_of_fit_gauss,inputs,5)))\n",
    "        te = time.time()\n",
    "\n",
    "    else:\n",
    "        assert False\n",
    "    \n",
    "    \n",
    "    results.append([lprob_l,pval_l])\n",
    "    \n",
    "    print('Elapsed time [minutes]: {}'.format((te-ts)/60.))\n",
    "    \n",
    "mypool.close()\n",
    "mypool.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "n,b,h = plt.hist(results[0][1],bins=200,histtype='step',label=imlist[0])\n",
    "for i,r in enumerate(imlist):\n",
    "    if i > 0:\n",
    "        plt.hist(results[i][1],bins=b,histtype='step',label=imlist[i]);\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,bz2\n",
    "\n",
    "with bz2.BZ2File('./Simulations_results/GOF_Helium.pbz2', 'w') as f:\n",
    "    dictosave = {'imlist':imlist,'results':results}\n",
    "    pickle.dump(dictosave,f)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
